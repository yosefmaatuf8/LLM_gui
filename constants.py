models_names = ['chat-gpt', 'LLaMa']
models = ['', '']  #AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir, quantization_config=quantization_config)

prompt_default = "e.g. what that inside the <> its the user messege"  # alwase applied
