models_names = ['chat-gpt', 'LLaMa']
models = ['', '']  #AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir, quantization_config=quantization_config)

PROMPT_DEFAULT = "wret"  # alwase applied
